{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGCwhCOx_9BR"
      },
      "source": [
        "<h1><center>Sistemas Distribuídos – 2023/1\n",
        "\n",
        "Prof. Rodolfo da Silva Villaça – rodolfo.villaca@ufes.br \\\\\n",
        "Monitor: Eduardo M. Moraes Sarmento – eduardo.sarmento@ufes.br\n",
        "\n",
        "Laboratório II – Aprendizado Federado usando a biblioteca Flower</h1></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfbB0PxwAq-q"
      },
      "source": [
        "<u>Objetivo</u>:\\\n",
        "Experimentar o treinamento de modelos de aprendizado de máquina por meio do *framework* de aprendizado *flwr*, disponível na biblioteca *flower* Comparar os resultados atingidos pelo modelo treinado de maneira local e federada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh8VLSKIFsFV"
      },
      "source": [
        "Este roteiro de laboratório foi testado usando o [Google Colab](https://colab.research.google.com/), ambiente de desenvolvimento colaborativo Python disponibilizado pelo Google como um serviço em nuvem.\\\n",
        "\\\n",
        "Para a execução do código deste roteiro são necessárias as bibliotecas *tensorflow* (versão 2.12.0), *numpy* (versão 1.22.4), *ray* (versão 2.2.0), *matplotlib* (versão 3.7.1) e *flower* (versão 1.3.0). As quatro primeiras já vem instaladas no **Google Colab**,. ntão, caso esteja executando por ele, não é necessária sua instalação. A biblioteca flower não vem instalada,  então precisamos instalá-la, e também o seu módulo de simulação, para podermos simular o treinamento federado no *notebook*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzNS6Vh14t8O"
      },
      "source": [
        "A célula seguinte executa a instalação de todas as bibliotecas necessárias. Caso esteja fora do Colab, é preciso descomentar as linhas de 3 a 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR5l58I7JhXc",
        "outputId": "3ec18206-0a9e-4af3-8ac4-a4d5802098ef"
      },
      "outputs": [],
      "source": [
        "!pip install flwr==1.3.0\n",
        "!pip install -U flwr[\"simulation\"]\n",
        "!pip install ray==2.2.0\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install numpy==1.22.4\n",
        "!pip install matplotlib==3.7.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt4gBsQ7VYUA"
      },
      "source": [
        "###Célula de Importação "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wD8STHmJcZZ"
      },
      "source": [
        "Importamos a biblioteca *os*, que lida com o sistema operacional. Utilizamos ela para configurar a *flag* \"TF_CPP_MIN_LOG_LEVEL\" com o valor 3, isto faz com que os logs do *tensorflow* sejam menos verbosos durante o treinamento.\\\n",
        "Depois, importamos as demais bibliotecas: \n",
        "\n",
        "1.   *flower*, para efetuar o aprendizado federado;\n",
        "2.   *tensorflow*, para definir uma arquitetura de rede neural, incluindo todas as camadas e otimizador que usaremos;\n",
        "3.   *numpy*, biblioteca de maniupulação eficiente de vetores numéricos;\n",
        "4.   *ray*, biblioteca utilizada pelo *flower* para instanciar a simulação do aprendizado federado.\n",
        "5.   *matplotlib*, biblioteca para plotar gráficos.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dwfd_R6JSkE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Make TensorFlow logs less verbose\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import flwr as fl\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D,Flatten,Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import ray\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMrrg_-wTSSg"
      },
      "source": [
        "#### Importação e Pré-rocessamento dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpgFLN0YGu2P"
      },
      "source": [
        "Neste laboratório usaremos o *dataset* MNIST, muito usado como referência na literatura. Este *dataset* é composto por imagens monocromáticas de 28 por 28 píxels (*28x28*), representando dígitos de 0 a 9 escritos a mão e anotadas com o valor do dígito. Ele contém dois *subdatasets*: o de treino e o de teste. O *subdataset* de treino é formado por 60 mil imagens, enquanto o *subdataset* de treino contém 10 mil imagens.\n",
        "\n",
        "O *tensorflow* já nos provê esse *dataset*, separando os *subdatasets* de treino entre: atributos alvo, tambem chamados de classes ou *targets* (*y_train e y_test*), e atributos não alvo (*x_train* e *x_test*), ou *features*. Sendo assim, para carregar este *dataset* basta instanciar (atribuição da variavel *mnist*) e carregar (método *load_data*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh4cJYFwJuWl"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bhElqYx8io1"
      },
      "source": [
        "Plotamos, como exemplo, os 10 primeiros dígitos do *dataset* de treino com suas classes. Por meio desse *plot* conseguiremos visualizar bem o tipo de dado que o *dataset* descreve.\n",
        "\n",
        " Vemos que as classes são o valor numérico que o digito representa e as imagens são dígitos escritos a mão, em preto e branco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "YqbYR3v-7DyU",
        "outputId": "5613c6e1-4faa-4b79-efda-7e52bf1d3728"
      },
      "outputs": [],
      "source": [
        "num = 10\n",
        "images = x_train[:num]\n",
        "labels = y_train[:num]\n",
        "num_row = 2\n",
        "num_col = 5\n",
        "# plot images\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "for i in range(num):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[i]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__UjhTmBJBaY"
      },
      "source": [
        "**Pré-Processamento dos Dados**\n",
        "\n",
        " Primeiro trabalhamos com os dados dos atributos não alvo (*features*), checando o formato dos *datasets* nas variáveis *x_train e x_test*. emos que eles têm os formatos (60000, 28, 28) e (10000, 28, 28) respectivamente.\n",
        "\n",
        " O primeiro número indica a quantidade de imagens contidas em cada *dataset*: 60000 para o treino e 10000 para o teste. Os outros dois números são a quantidade de pixeis de cada imagem, 28 píxeis verticais e 28 píxeis horizontais.\n",
        "\n",
        "Sendo assim, cada imagem é representada como matrizes de números (28 x 28). Já que as imagens são monocromáticas, cada elemento da matriz significa a luminosidade doassociad àquela posição do *pixel*,em valores que vão de 0 a 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU2vN7wXJpMR",
        "outputId": "68ea74bb-cd29-4f00-a667-a751b839c62a"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2-4DkEMOfzR"
      },
      "source": [
        "Para usar os *datasets* no treinamento e teste de modelos de aprendizado de máquina é necessario, inicialmente, pré-processar os dados.\n",
        "\n",
        "Primeiro fazemos o *reshape*, incluindo uma nova dimensão que indica que as imagens são monocromaticas (*reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)*). \n",
        "\n",
        "Depois normalizamos os dados dos atributos não alvo, dividindo os valores de luminosidade dos pixeis pelo maior valor possivel, *255*, com isso fazendo com que estes valores fiquem na faixa entre 0 e 1. \n",
        "\n",
        "Com essas duas ações encerramos  pré-processamento dos atributos não alvo (*features*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW1ZnGTP7BY3"
      },
      "outputs": [],
      "source": [
        "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train=x_train / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "x_test=x_test/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_Yh2zuQTTx"
      },
      "source": [
        "Para os atributos alvo (*target*) é necessário fazer o *one hot enconding* das classes. Esta operação consistem em transformar as classes adicionando novas colunas, que indicam a presença ou não da classe. Isto é, como neste *dataset* as classes são os números de 0 a 9, adicionamos 9 novas colunas, numeradas de 0 a 9. Para cada amostra, cada uma destas novas colunas terá os valores 0 ou 1, onde 0 indica   que a amostra não é daquela classe e 1 indica que a amostra é daquela classe. \n",
        "\n",
        "Printamos a primeira amostra do conjunto de treinamento , antes e depois da aplicação da operação, para vermos seu efeito sobre a amostra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT-Dx92e4_IG",
        "outputId": "d16bfec0-31eb-4f79-89f7-6ae7f2655910"
      },
      "outputs": [],
      "source": [
        "print(y_train[0])\n",
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVboMW3UTdOp"
      },
      "source": [
        "#### Treinamento Local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgSqVuHrQcla"
      },
      "source": [
        "A técnica de aprendizado federado foi desenvolvida inicialmente para o treinamento de redes neurais, por isso precisamos definir uma rede neural para podermos usá-la localmente e,  futuramente, comparar os  resultados do  modelos gerados localmente e federado.\n",
        "\n",
        "Esta próxima célula define uma função que monta uma rede neural convolucional simples, que usaremos na etapa de treinamento. A rede neural recebe como atributos: o formato dos dados de entrada (*input_shape*) e o numero de classes do problema (*num_classes*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WcxuXm3AK-n"
      },
      "outputs": [],
      "source": [
        "def define_model(input_shape,num_classes):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
        "  model.add(MaxPool2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPW2kMNcRtzX"
      },
      "source": [
        "Conforme explicado anteriorment,  após o pré-processamento,  cada imagem do *dataset* terá o seguinte formato: 28 pixeis verticais, 28 pixeis horizontais e 1 canal de cor. Desta forma o formato de entrada dos dados é (28, 28, 1). \n",
        "\n",
        "Temos digitos de 0 a 9 em nosso *dataset*, ou seja, 10 possiveis classes. Com isso instanciamos uma rede neural usando a função *define_model* na variavel model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GycOgcz7JFs"
      },
      "outputs": [],
      "source": [
        "input_shape = (28, 28, 1)\n",
        "num_classes = 10\n",
        "\n",
        "model = define_model(input_shape,num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0VpTq8oShd4"
      },
      "source": [
        "Inicialmente treinaremos a rede neural localmente para termos um *baseline* de comparação. A rede neural  é treinada por 5 épocas, usando 10% do *dataset* de treino para validação durante o treinamento. \n",
        "\n",
        "Usamos 64 como *batch_size*, isso significa que  expomos a rede neural a 64 amostras (lote, ou *batch*) antes de atualizarmos o valor da função de perda. Esse processo  é repetido até que todas as amostras tenham sido expostas à rede neural, terminando uma época de treinamento. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjWO0dJa7VL-",
        "outputId": "4fc3cb20-ff4d-4682-9619-aa78af018384"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 5\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WftT7AFCSud_"
      },
      "source": [
        "Como conclusão, com o conjunto de teste usado neste laboratório, e usando  o nosso modelo,  obtivemos uma acurácia de ~98,39%, que é um resultado aceitável com relação a este *dataset*, comparando-se com os resultados de referência encontrados na literatura. Ver [referência](https://paperswithcode.com/sota/image-classification-on-mnist)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXIiIk8d7eGS",
        "outputId": "7b78060d-98fa-491c-ebf9-f8644230ff0a"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR1XwzYWTiOa"
      },
      "source": [
        "#### Treinamento Federado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3dPiK8tVRn1"
      },
      "source": [
        "Agora começaremos o treinamento federado desta mesma rede neural usando a biblioteca *flower*. Esta biblioteca implementa a arquitetura de aprendizado federado, onde no treinamento temos dois agentes: o servidor e os clientes. \n",
        " \n",
        "* Os clientes (treinadores) têm como tarefa treinar seus modelos usando seus dados locais e, após o treinamento, enviar os pesos encontrados para o servidor de agregação. Quando receberem os pesos agregados pelo servidor, os clientes atualizam seus modelos locai com estes pesos e recomeçam o treinamento, assim iniciando uma nova rodada (época).\n",
        "* O servidor de agregação, por sua vez, recebe estes pesos e usa algum algoritmo para agregar os diferentes pesos dos modelos gerados pelos clientes treinadores. Em seguida o servidor deve enviar de volta os pesos agregados para os clientes. \n",
        "\n",
        "Ao final desse processo,  os  pesos agregados representam o modelo global que está sendo treinado por esse conjunto de treinadores.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTwlQHH6W5Fa"
      },
      "source": [
        "Sabendo disso, para o uso da biblioteca *flower* temos, como primeiro passo, que implementar o código dos clientes. Para isso definimos uma classe cliente que herda da super classe *NumPyClient* provida pela biblioteca *numpy*. Para seu uso temos que implementar obrigatoriamente 3 métodos em nosso cliente:\n",
        "\n",
        "\n",
        "1.  *get_parameters(self, config)*: este método recebe um dicionário de configuração e é chamado pelo servidor como um procedimento remoto. Ele retorna os pesos do modelo do cliente na rodada atual.\n",
        "2.  *fit(self, parameters, config)*: por este método, chamado via RPC pelo servidor, o cliente recebe os pesos do modelo global e um dicionário de configuração. Ele realiza o treinamento do modelo, primeiro setando os pesos do modelo com os recebidos pelo cliente do servidor e depois treinando um novo modelo com esses novos pesos iniciais. Ela retorna: os pesos encontrados após essa rodada de treinamento, o tamanho do conjunto de treinamento e um dicionário de métricas de avaliação do modelo. O dicionário pode ser retornado vazio.\n",
        "3.  *evaluate(self, parameters, config)*: por este método, chamado remotamente pelo servidor, o cliente recebe os pesos do modelo global e um dicionário de configuração. Ele avalia localmente o modelo treinado e retorna o valor da função de perda encontrado para este cliente, o tamanho do conjunto de teste e um dicionário de métricas de avaliação do modelo. Neste caso, retornaremos a acurácia.\n",
        "\n",
        "Também definimos um método opcional *\\_\\_init\\_\\_(self, model, x_train, y_train, x_test, y_test)* que é o de inicialização do objeto, recebendo o modelo pré-instanciado e os conjuntos de teste e treino.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9mL7lqLWQTG"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_test, y_test) -> None:\n",
        "        self.model = model\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=2)\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc = self.model.evaluate(self.x_test, self.y_test, verbose=2)\n",
        "        return loss, len(self.x_test), {\"accuracy\": acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkXB2eVJbeQk"
      },
      "source": [
        "Como estamos usando um *notebook*, não podemos instanciar clientes e servidores do *flower* diretamente. Por isso a biblioteca prove uma alternativa que é o módulo de simulação. Ele simula o aprendizado federado sem o uso de conexões de rede.\\\n",
        "\\\n",
        "Para o seu uso temos que definir uma função que instancias os clientes com a assinatura *fn(str) -> fl.client.Client*. Esta função recebe uma *string* que é um identificador único do cliente usado pela simulação e nos retorna o cliente instanciado. Internamente ela particiona o *dataset*, amostrando, sem reposição, um número aleatório de imagens, compondo um conjunto de dados que representa os dados locais daquele cliente. \n",
        "\n",
        "A seguir faremos os mesmos passos anteriores de pré-processamento e instanciamento da rede neural. Finalmente instanciaremos um cliente *flower* e retornamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHd05AShiI46"
      },
      "outputs": [],
      "source": [
        "def client_fn_random(cid: str) -> fl.client.Client:\n",
        "    input_shape = (28, 28, 1)\n",
        "    num_classes = 10\n",
        "    num_clients = 10\n",
        "    partition_size = 500\n",
        "    \n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    #sample_size_train = int(cid) * partition_size\n",
        "    #sample_size_test = int(cid) * partition_size\n",
        "    sample_size_train = int((1/num_clients)*len(x_train))\n",
        "    sample_size_test = int((1/num_clients)*len(x_test))\n",
        "    idx_train = np.random.choice(np.arange(len(x_train)), sample_size_train, replace=False)\n",
        "    x_train = x_train[idx_train]/255.0\n",
        "    y_train = y_train[idx_train]\n",
        "    y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "    idx_test = np.random.choice(np.arange(len(x_test)), sample_size_test, replace=False)\n",
        "    x_test = x_test[idx_test]/255.0\n",
        "    y_test = y_test[idx_test]\n",
        "    y_test = tf.one_hot(y_test.astype(np.int32), depth=10)\n",
        "    model = define_model(input_shape,num_classes)\n",
        "    # Create and return client\n",
        "    return FlowerClient(model, x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txp65BZCdFkD"
      },
      "source": [
        "Para a avaliação do modelo precisamos de uma função de agregação de métricas. Isto é necessário pois, a priori, a simulação não sabe que tipo de métrica será usada para avaliar o modelo. Por isso o programador tem que criar uma função que lide com a agregação dos valores de métricas que ele esta usando para avaliar seu modelo. Desta maneira esta função é usada para que a simulação consiga retornar a evolução dos valores das métricas em cada *round* usando um objeto do tipo *history*.\n",
        "\n",
        "\n",
        "Aqui definimos a função de agregação como a média ponderada da acurácia pelo tamanho do conjunto de dados de cada cliente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZZ0onPuExOM"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics):\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    acc = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    results = {\"accuracy\": sum(acc) / sum(examples)}\n",
        "    return results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1VQnCBXtd0fr"
      },
      "source": [
        "Precisamos agora definir o número de clientes que participação do aprendizado federado, 10 clientes neste exemplo, e uma estratégia de agregação dos pesos a ser usada pelo servidor.\n",
        "\n",
        "Esta estratégia é um objeto do tipo *strategy* da biblioteca *flower*. Além de definir o algoritmo de agregação dos pesos, no caso usamos o *Federated Average (FedAvg)*, também é preciso configurar o comportamento do servidor durante o processo de treinamento. Com essa biblioteca nós configuramos o servidor para:\n",
        "\n",
        "- 1.   Escolher aleatoriamente 90% dos clientes (9 clientes neste exemplo) para o treinamento (*fraction_fit*);\n",
        "- 2.   Usar todos os clientes para a avaliação do modelo (*fraction_evaluate*);\n",
        "- 3.   Nunca usar menos que 9 clientes para o treinamento (*min_fit_clients*);\n",
        "- 4.   Nunca usar menos que 9 clientes para a avaliação do modelo (*min_evaluate_clients*);\n",
        "- 5.   Esperar que tenha pelo menos 9 clientes prontos antes de começar o treinamento(*min_available_clients*);\n",
        "- 6.   Usar a função *weighted_average*, definida anteriormente, como função de agregação de métricas\n",
        "\n",
        "Finalmente iniciamos a simulação usando a função *fl.simulation.start_simulation*. Passamos para essa função a função de instanciamento de clientes (*client_fn_random*), o número de clientes (*num_clients*), um dicionário de configuração, que diz para o servidor quantos *rounds* de treinamento queremos (*fl.server.ServerConfig(num_rounds=5)*) e a estratégia de treinamento (*strategy*). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRvT4OOdXADa",
        "outputId": "bb3b750a-fa1d-4c53-b3fa-ffc9cd409040"
      },
      "outputs": [],
      "source": [
        "num_clients = 10\n",
        "\n",
        "# Create FedAvg strategy\n",
        "print(\"creating strategy\")\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.9,  \n",
        "    fraction_evaluate=1,  \n",
        "    min_fit_clients=9,  \n",
        "    min_evaluate_clients=9,  \n",
        "    min_available_clients=int(\n",
        "        num_clients * 0.9\n",
        "    ),  \n",
        "    evaluate_metrics_aggregation_fn=weighted_average,\n",
        ")\n",
        "\n",
        "print(\"starting simulation\")\n",
        "# Start simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_random,\n",
        "    num_clients=num_clients,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    strategy=strategy,\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjQznojrgy46"
      },
      "source": [
        "Printamos os resultados do treinamento retornados no formato do objeto *history*. Ele tem dois atributos: um dicionário com a média da função de perda a cada *round* e um dicionário com os valores das métricas agregadas a cada *round*, calculadas pela função de agregação. \n",
        "\n",
        "Podemos observar a evolução destes dois valores a cada *round*. Para os 4 primeiros *rounds* tivemos uma melhora do valor da função de perda e da acurácia, mas no último *round* a função de perda diminuiu pouco e a acurácia se manteve estável.\n",
        "\n",
        "O número de *rounds* de treinamento é um valor muito importante para o aprendizado federado. Similar ao número de épocas de treinamento no aprendizado local, precisamos de *rounds* suficientes para que o modelo convirja com pesos adequados, mas temos que tomar cuidado para não causar o *overfitting* da rede, caso tenhamos muitos *rounds*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLw296UPIIIw",
        "outputId": "57ce75a3-9dba-4fbb-d9cb-d69846206936"
      },
      "outputs": [],
      "source": [
        "print(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbSgu-8-lDm5"
      },
      "source": [
        "A seguir plotaremos a acurácia por *round*. Observe que ela parece estar tendendo a aumentar a cada *round* e, **talvez**, se aumentássemos o numero de *rounds* teríamos uma acurácia ainda melhor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "K0OJfjkxW9NX",
        "outputId": "1d0fb1f3-fc89-4ea2-9694-a3ae26b6e3d0"
      },
      "outputs": [],
      "source": [
        "plt.plot(*zip(*history.metrics_distributed['accuracy']))\n",
        "plt.ylim(0.9, 1)\n",
        "plt.xlabel(\"Rounds\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R6RJStQTnCc"
      },
      "source": [
        "#### Atividades"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n8LqayNw6xLV"
      },
      "source": [
        "**Atividade 1** \n",
        "\n",
        "Durante a configuração do treinamento federado definimos valores para muitos hyper-parâmetros. Um dos mais importantes é foi o número de *rounds*. Por isso nesta tarefa vocês deverão treinar a rede de maneira federada variando o número de rounds em diferentes valores. \n",
        "\n",
        " \n",
        "\n",
        "- *   Os valores a serem usados para o número de *rounds* são 10, 15, 20;\n",
        "- *   Para cada valor deve-se plotar um gráfico de linha que relaciona o número de *rounds* com a acurácia obtida naquele número de *rounds*.\n",
        "\n",
        "Além   disso deve-se comparar a desempenho do modelo federado com os diferentes valores de *rounds* e o  desempenho encontrado quando treinamos localmente a rede neural.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_clients = 10\n",
        "num_rounds = [10, 15, 20]\n",
        "\n",
        "# Create FedAvg strategy\n",
        "print(\"creating strategy\")\n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.9,  \n",
        "    fraction_evaluate=1,  \n",
        "    min_fit_clients=9,  \n",
        "    min_evaluate_clients=9,  \n",
        "    min_available_clients=int(\n",
        "        num_clients * 0.9\n",
        "    ),  \n",
        "    evaluate_metrics_aggregation_fn=weighted_average,\n",
        ")\n",
        "\n",
        "print(\"starting simulation\")\n",
        "# Start simulation\n",
        "histories = []\n",
        "for r in num_rounds:\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn_random,\n",
        "        num_clients=num_clients,\n",
        "        config=fl.server.ServerConfig(num_rounds=r),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "    \n",
        "    # plota grafico\n",
        "    plt.plot(*zip(*history.metrics_distributed['accuracy']))\n",
        "    plt.xlabel(\"Rounds\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjhS4hFxPoBt"
      },
      "source": [
        "**Atividade 2** \n",
        "\n",
        "Fizemos o aprendizado federado mediado por uma simulação, mas em um cenário real teríamos processos clientes, representando os treinadores, sendo executados em várias máquinas independentes, conectadas a um processo servidor (agregador) pela rede ou pela Internet, por exemplo. \n",
        "\n",
        "Como tarefa para casa deve-se  realizar o aprendizado federado de uma maneira mais próxima da realidade, usando processos diferentes para rodar os clientes e o servidor. \n",
        "\n",
        "Para isso será necessário criar 2 programas python, o *client.py* e o *server.py*: \n",
        "\n",
        "\n",
        "*   O *client.py* deve implementar uma classe que herda a classe  *NumpyClient*, fornecida pela biblioteca flower, instanciar um objeto dessa classe e se conectar ao servidor;\n",
        "*   O *server.py* deve configurar um servidor de aprendizado federado usando um objeto *strategy* e um objeto *serverConfigserverConfig*. Em seguida deve-se iniciar o servidor para realizar o aprendizado com (no mínimo) 5 clientes.\n",
        "\n",
        "O *server.py* e o *client.py* devem ser executados em terminais próprios. Isto é, deve se usar um minimo de  6 terminais na solução dessa tarefa: um para o  servidor e um para cada cliente (5 no mínimo). \n",
        "\n",
        "Ao final, plotar a acurácia para 2,5, 10, 20 e 40 *rounds* como a quantidade de clientes definida por você (mínimo  5).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06-xKYJVd_t-"
      },
      "source": [
        "Dicas:\n",
        "\n",
        "\n",
        "\n",
        "*   Não é necessário utilizar várias máquinas para isso;\n",
        "\n",
        "*    Nesta atividade podemos emular uma rede por meio da interface de rede *localhost* (IP: 127.0.0.1) onde os processos treinadores e servidores podem ser executados em terminais Linux separados conectando-se pelo endereço IP 127.0.0.1;\n",
        "*   Como referência, usem a [documentação da biblioteca *flower*](https://flower.dev/docs/) na Seção QuickStart tutorials: tensorflow\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
